{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157139f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\" ImageNet Training Script\n",
    "\n",
    "This is intended to be a lean and easily modifiable ImageNet training script that reproduces ImageNet\n",
    "training results with some of the latest networks and training techniques. It favours canonical PyTorch\n",
    "and standard Python style over trying to be able to 'do it all.' That said, it offers quite a few speed\n",
    "and training result improvements over the usual PyTorch example scripts. Repurpose as you see fit.\n",
    "\n",
    "This script was started from an early version of the PyTorch ImageNet example\n",
    "(https://github.com/pytorch/examples/tree/master/imagenet)\n",
    "\n",
    "NVIDIA CUDA specific speedups adopted from NVIDIA Apex examples\n",
    "(https://github.com/NVIDIA/apex/tree/master/examples/imagenet)\n",
    "\n",
    "Hacked together by / Copyright 2020 Ross Wightman (https://github.com/rwightman)\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('/cephfs/juxin/QwT/QwT-cls-RepQ-ViT')\n",
    "import argparse\n",
    "import copy\n",
    "import random\n",
    "import socket\n",
    "from contextlib import suppress\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.distributed\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data\n",
    "from timm.data import Mixup\n",
    "from timm.data.dataset import ImageDataset\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.utils import random_seed, NativeScaler, accuracy\n",
    "from torch.amp import autocast as amp_autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as NativeDDP\n",
    "from timm.scheduler.scheduler_factory import CosineLRScheduler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from quant import *\n",
    "from utils import *\n",
    "from utils.utils import write, create_transform, create_loader, AverageMeter, broadcast_tensor_from_main_process, gather_tensor_from_multi_processes, compute_quantized_params\n",
    "\n",
    "HOST_NAME = socket.getfqdn(socket.gethostname())\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "LINEAR_COMPENSATION_SAMPLES = 128\n",
    "\n",
    "def seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class CompensationBlock(nn.Module):\n",
    "    def __init__(self, W, b, r2_score, block, linear_init=True, local_rank=0, block_id=None):\n",
    "        super(CompensationBlock, self).__init__()\n",
    "        self.block = block\n",
    "\n",
    "        self.lora_weight = nn.Parameter(torch.zeros((W.size(0), W.size(1))))\n",
    "        self.lora_bias = nn.Parameter(torch.zeros(W.size(1)))\n",
    "\n",
    "        if linear_init and (r2_score > 0):\n",
    "            self.lora_weight.data.copy_(W)\n",
    "            self.lora_bias.data.copy_(b)\n",
    "            if local_rank == 0:\n",
    "                _write('block {} using linear init'.format(block_id))\n",
    "        else:\n",
    "            nn.init.zeros_(self.lora_weight)\n",
    "            nn.init.zeros_(self.lora_bias)\n",
    "            if local_rank == 0:\n",
    "                _write('block {} using lora init'.format(block_id))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        if self.training:\n",
    "            lora_weight = self.lora_weight.float()\n",
    "            out = out + x @ lora_weight + self.lora_bias\n",
    "        else:\n",
    "            # QwT layers run in half mode\n",
    "            lora_weight = self.lora_weight.half()\n",
    "            out = out + (x.half() @ lora_weight).float() + self.lora_bias\n",
    "\n",
    "        return out\n",
    "\n",
    "def enable_quant(submodel):\n",
    "    for name, module in submodel.named_modules():\n",
    "        if isinstance(module, QuantConv2d) or isinstance(module, QuantLinear) or isinstance(module, QuantMatMul):\n",
    "            module.set_quant_state(True, True)\n",
    "\n",
    "def disable_quant(submodel):\n",
    "    for name, module in submodel.named_modules():\n",
    "        if isinstance(module, QuantConv2d) or isinstance(module, QuantLinear) or isinstance(module, QuantMatMul):\n",
    "            module.set_quant_state(False, False)\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item]\n",
    "\n",
    "def lienar_regression(X, Y, block_id=0):\n",
    "    X = X.reshape(-1, X.size(-1))\n",
    "\n",
    "    X = gather_tensor_from_multi_processes(X, world_size=args.world_size)\n",
    "\n",
    "    X_add_one = torch.cat([X, torch.ones(size=[X.size(0), ], device=X.device).reshape(-1, 1)], dim=-1)\n",
    "    Y = Y.reshape(-1, Y.size(-1))\n",
    "\n",
    "    Y = gather_tensor_from_multi_processes(Y, world_size=args.world_size)\n",
    "\n",
    "    # _write('the shape of X_add_one is {}, Y is {}'.format(X_add_one.size(), Y.size()))\n",
    "\n",
    "    X_add_one_T = X_add_one.t()\n",
    "    W_overall = torch.inverse(X_add_one_T @ X_add_one) @ X_add_one_T @ Y\n",
    "\n",
    "    W = W_overall[:-1, :]\n",
    "    b = W_overall[-1, :]\n",
    "\n",
    "    Y_pred = X @ W + b\n",
    "\n",
    "    abs_loss = (Y - Y_pred).abs().mean()\n",
    "\n",
    "    ss_tot = torch.sum((Y - Y.mean(dim=0)).pow(2))\n",
    "    ss_res = torch.sum((Y - Y_pred).pow(2))\n",
    "    r2_score = 1 - ss_res / ss_tot\n",
    "\n",
    "    # _write('block : {}      abs : {:.6f}      r2 : {:.3f}'.format(block_id, abs_loss, r2_score))\n",
    "\n",
    "    return W, b, r2_score\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model\", default=\"vit_small\", choices=['vit_small', 'vit_base', 'deit_tiny', 'deit_small', 'deit_base', 'deit_tiny_distilled', 'deit_small_distilled', 'deit_base_distilled'], help=\"model\")\n",
    "parser.add_argument('--data_dir', default='../ImageNet', type=str)\n",
    "\n",
    "parser.add_argument('--w_bits', default=4, type=int, help='bit-precision of weights')\n",
    "parser.add_argument('--a_bits', default=4, type=int, help='bit-precision of activation')\n",
    "parser.add_argument('--start_block', default=0, type=int)\n",
    "\n",
    "parser.add_argument(\"--batch_size\", default=32, type=int, help=\"batchsize of validation set\")\n",
    "parser.add_argument('--num_workers', default=4, type=int)\n",
    "parser.add_argument(\"--seed\", default=0, type=int, help=\"seed\")\n",
    "\n",
    "parser.add_argument(\"--local-rank\", default=0, type=int)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "train_aug = 'large_scale_train'\n",
    "test_aug = 'large_scale_test'\n",
    "args.drop_path = 0.0\n",
    "args.num_classes = 1000\n",
    "\n",
    "model_type = args.model.split(\"_\")[0]\n",
    "if model_type == \"deit\":\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.875\n",
    "elif model_type == 'vit':\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    crop_pct = 0.9\n",
    "elif model_type == 'swin':\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    crop_pct = 0.9\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "args.distributed = False\n",
    "if 'WORLD_SIZE' in os.environ:\n",
    "    args.distributed = int(os.environ['WORLD_SIZE']) > 1\n",
    "args.device = 'cuda:0'\n",
    "args.world_size = 1\n",
    "args.rank = 0  # global rank\n",
    "if args.distributed:\n",
    "    args.device = 'cuda:%d' % args.local_rank\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "    args.world_size = torch.distributed.get_world_size()\n",
    "    args.rank = torch.distributed.get_rank()\n",
    "\n",
    "assert args.rank >= 0\n",
    "\n",
    "\n",
    "args.log_dir = os.path.join('checkpoint', args.model, 'QwT', 'bs_{}_worldsize_{}_w_{}_a_{}_startblock_{}_sed_{}'.format(args.batch_size, args.world_size, args.w_bits, args.a_bits, args.start_block, args.seed))\n",
    "\n",
    "args.log_file = os.path.join(args.log_dir, 'log.txt')\n",
    "\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    if not os.path.exists(args.log_dir):\n",
    "        os.makedirs(args.log_dir)\n",
    "\n",
    "    if os.path.isfile(args.log_file):\n",
    "        os.remove(args.log_file)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "_write = partial(write, log_file=args.log_file)\n",
    "\n",
    "if args.distributed:\n",
    "    _write('Training in distributed mode with multiple processes, 1 GPU per process. Process %d, total %d.' % (args.rank, args.world_size))\n",
    "else:\n",
    "    _write('Training with a single process on 1 GPUs.')\n",
    "assert args.rank >= 0\n",
    "\n",
    "\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    _write(args)\n",
    "\n",
    "seed(args.seed)\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    _write('dataset mean : {} & std : {}'.format(mean, std))\n",
    "\n",
    "dataset_train = ImageDataset(root=os.path.join(args.data_dir, 'train'), transform=create_transform(train_aug, mean, std, crop_pct))\n",
    "dataset_eval = ImageDataset(root=os.path.join(args.data_dir, 'val'), transform=create_transform(test_aug, mean, std, crop_pct))\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    _write('len of train_set : {}    train_transform : {}'.format(len(dataset_train), dataset_train.transform))\n",
    "    _write('len of eval_set : {}    eval_transform : {}'.format(len(dataset_eval), dataset_eval.transform))\n",
    "\n",
    "loader_train = create_loader(\n",
    "    dataset_train,\n",
    "    batch_size=args.batch_size,\n",
    "    is_training=True,\n",
    "    re_prob=0.0,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    num_workers=args.num_workers,\n",
    "    distributed=args.distributed,\n",
    "    log_file=args.log_file,\n",
    "    drop_last=True,\n",
    "    local_rank=args.local_rank,\n",
    "    persistent_workers=False\n",
    ")\n",
    "loader_eval = create_loader(\n",
    "    dataset_eval,\n",
    "    batch_size=args.batch_size,\n",
    "    is_training=False,\n",
    "    re_prob=0.,\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    num_workers=args.num_workers,\n",
    "    distributed=args.distributed,\n",
    "    log_file=args.log_file,\n",
    "    drop_last=False,\n",
    "    local_rank=args.local_rank,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "model_zoo = {\n",
    "    'vit_small' : 'vit_small_patch16_224',\n",
    "    'vit_base' : 'vit_base_patch16_224',\n",
    "\n",
    "    'deit_tiny' : 'deit_tiny_patch16_224',\n",
    "    \"deit_tiny_distilled\" : \"deit_tiny_distilled_patch16_224\",\n",
    "    'deit_small': 'deit_small_patch16_224',\n",
    "    \"deit_small_distilled\": \"deit_small_distilled_patch16_224\",\n",
    "    'deit_base' : 'deit_base_patch16_224',\n",
    "    \"deit_base_distilled\": \"deit_base_distilled_patch16_224\",\n",
    "}\n",
    "#Quant using RepQ-ViT\n",
    "_write('Building model ...')\n",
    "model = build_model(model_zoo[args.model], args)\n",
    "model.to(args.device)\n",
    "'''\n",
    "model.eval()\n",
    "top1_acc_eval = validate(model, loader_eval)\n",
    "_write('base eval_acc: {:.2f}'.format(top1_acc_eval.avg))\n",
    "with open(f'log/{args.model}/acc.log', 'a') as f:\n",
    "    f.writelines(f'base: {top1_acc_eval.avg}\\n')\n",
    "base_model = copy.deepcopy(model)\n",
    "wq_params = {'n_bits': args.w_bits, 'channel_wise': True}\n",
    "aq_params = {'n_bits': args.a_bits, 'channel_wise': False}\n",
    "# q_model = quant_model(model, input_quant_params=aq_params, weight_quant_params=wq_params)\n",
    "'''\n",
    "q_model = model\n",
    "q_model.to(args.device)\n",
    "q_model.eval()\n",
    "\n",
    "os.makedirs(f'log/{args.model}', exist_ok=True)\n",
    "with open(f'log/{args.model}/structure_quant.txt', 'w') as f:\n",
    "    f.write(str(q_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6059221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to generate compensation model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.52it/s]\n",
      "3it [00:00, 34.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 0 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 44.65it/s]\n",
      "3it [00:00, 37.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 1 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 37.29it/s]\n",
      "3it [00:00, 34.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 2 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 42.85it/s]\n",
      "3it [00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 3 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 52.43it/s]\n",
      "3it [00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 4 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 44.64it/s]\n",
      "3it [00:00, 37.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 5 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 47.89it/s]\n",
      "3it [00:00, 38.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 6 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00, 38.21it/s]\n",
      "3it [00:00, 38.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 7 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 48.93it/s]\n",
      "3it [00:00, 37.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 8 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 29.97it/s]\n",
      "3it [00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 9 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 30.86it/s]\n",
      "3it [00:00, 37.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 10 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 43.35it/s]\n",
      "3it [00:00, 38.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 11 using lora init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 52.69it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('log/123.log', 'w')\n",
    "@torch.no_grad()\n",
    "def generate_compensation_model(q_model, train_loader, args):\n",
    "    _write('start to generate compensation model')\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    output_t = torch.zeros(size=[0,], device=args.device)\n",
    "    f.writelines(f'LINEAR_COMPENSATION_SAMPLES: {LINEAR_COMPENSATION_SAMPLES}\\n')\n",
    "    for i, (image, _) in tqdm(enumerate(train_loader)):\n",
    "        f.writelines(f'image.shape: {image.shape}\\t')\n",
    "        image = image.cuda()\n",
    "        t_out = q_model.forward_before_blocks(image)\n",
    "        f.writelines(f't_out.shape: {t_out.shape}\\n')\n",
    "        output_t = torch.cat([output_t, t_out.detach()], dim=0)\n",
    "        torch.cuda.synchronize()\n",
    "        if i >= (LINEAR_COMPENSATION_SAMPLES // args.batch_size // args.world_size - 1):\n",
    "            break\n",
    "\n",
    "    f.writelines(f'output_t.shape: {output_t.shape}\\n')\n",
    "    feature_set = FeatureDataset(output_t.detach().cpu())\n",
    "    feature_loader = torch.utils.data.DataLoader(feature_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "    output_previous = output_t\n",
    "    for block_id in range(len(q_model.blocks)):\n",
    "\n",
    "        feature_set.X = output_previous.detach().cpu()\n",
    "\n",
    "        block = q_model.blocks[block_id]\n",
    "        output_full_precision = torch.zeros(size=[0, ], device=args.device)\n",
    "        output_quant = torch.zeros(size=[0, ], device=args.device)\n",
    "        output_t_ = torch.zeros(size=[0, ], device=args.device)\n",
    "        for i, t_out in tqdm(enumerate(feature_loader)):\n",
    "            t_out = t_out.cuda()\n",
    "            if block_id == 0:\n",
    "                f.writelines(f't_out=output_t[i*32:i*32+32,:,:]: {output_t[i*32:i*32+32,:,:].equal(t_out)}\\n')\n",
    "            disable_quant(block)\n",
    "            full_precision_out = block(t_out)\n",
    "            if block_id == 0:\n",
    "                f.writelines(f't_out.shape: {t_out.shape}\\t')\n",
    "                f.writelines(f'full_precision_out.shape: {full_precision_out.shape}\\n')\n",
    "\n",
    "            enable_quant(block)\n",
    "            quant_out = block(t_out)\n",
    "\n",
    "            output_t_ = torch.cat([output_t_, t_out.detach()], dim=0)\n",
    "            output_full_precision = torch.cat([output_full_precision, full_precision_out.detach()], dim=0)\n",
    "            output_quant = torch.cat([output_quant, quant_out.detach()], dim=0)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            if i >= (LINEAR_COMPENSATION_SAMPLES // args.batch_size  // args.world_size - 1):\n",
    "                break\n",
    "\n",
    "        assert torch.sum((output_previous - output_t_).abs()) < 1e-3\n",
    "        if block_id == 0:\n",
    "            f.writelines(f'output_t_.shape: {output_t_.shape} {output_full_precision.shape}\\n')\n",
    "        W, b, r2_score = lienar_regression(output_t_, output_full_precision - output_quant, block_id=block_id)\n",
    "        q_model.blocks[block_id] = CompensationBlock(W=W, b=b, r2_score=r2_score, block=q_model.blocks[block_id], linear_init=True if block_id >= args.start_block else False, local_rank=args.local_rank, block_id=block_id)\n",
    "        q_model.cuda()\n",
    "\n",
    "        qwerty_block = q_model.blocks[block_id]\n",
    "\n",
    "        output_previous = torch.zeros(size=[0, ], device=args.device)\n",
    "        for i, t_out in tqdm(enumerate(feature_loader)):\n",
    "            t_out = t_out.cuda()\n",
    "            enable_quant(qwerty_block)\n",
    "            previous_out = qwerty_block(t_out)\n",
    "\n",
    "            output_previous = torch.cat([output_previous, previous_out.detach()], dim=0)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            if i >= (LINEAR_COMPENSATION_SAMPLES // args.batch_size // args.world_size - 1):\n",
    "                break\n",
    "\n",
    "    return q_model\n",
    "\n",
    "q_model = generate_compensation_model(q_model, loader_train, args)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
