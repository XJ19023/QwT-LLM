>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

>>>> LlamaForCausalLM <<<<input_ids type: <class 'torch.Tensor'> torch.Size([1, 2048])
attention_mask type: <class 'NoneType'> None
position_ids type: <class 'NoneType'> None
past_key_values type: <class 'NoneType'> None
inputs_embeds type: <class 'NoneType'> None
use_cache type: <class 'NoneType'> None
output_attentions type: <class 'bool'> False
output_hidden_states type: <class 'bool'> False
cache_position type: <class 'NoneType'> None

